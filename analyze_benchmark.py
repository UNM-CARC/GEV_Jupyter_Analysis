#!/usr/bin/env python

# This notebook reads the data generated by the data generator program and both sanity check it and post process it to generate BSP interval lengths that can be analyzed to understand and/or prediction application behavior.

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import scipy
from scipy.stats import genextreme
from scipy import stats
import os, glob
from math import factorial as fac
from fractions import Fraction as mpq

import mlflow
import gevfit

def construct_dataframe(file):
	iterdata = pd.read_json(file, orient='records')
	iterdata = iterdata[iterdata['rank'] == 0]
	iterdata = iterdata.sort_values(['uniq_id', 'iteration', 'rank']).reset_index(drop=True)

	iterdata = iterdata.drop(['work_start', 'barrier_start', 'barrier_end'] , axis=1)

	return iterdata

# Calculation of harmonic numbers taken from
# http://fredrik-j.blogspot.com/2009/02/how-not-to-compute-harmonic-numbers.html
def _harmonic(a, b):
    if b-a == 1:
        return 1, int(a)
    m = (a+b)//2
    p, q = _harmonic(a,m)
    r, s = _harmonic(m,b)
    return p*s+q*r, q*s

def harmonic(n):
    return mpq(*_harmonic(1,n+1))

def emma(dist, p):
	return dist.ppf((0.570376002)**(1/p))


# Info on how to map GSL distributions to scipy distributions and project
# them to larger scales.
distmap = { 'gaussian':	{'name':'norm',
			 'dist':stats.norm,
			 'translate': lambda a, b: (a, b),
			 'project': emma},
            'exponential':{'name':'expon',
			   'dist':stats.expon ,
			   'translate': lambda a, b: (0, a),
			   'project': lambda d, r: harmonic(r)*d.moment(1)},
            'uniform':	{'name':'uniform',
			 'dist':stats.uniform,
			 'translate': lambda a, b: (a, b),
			 'project': emma},
            'pareto':	{'name':'pareto',
			 'dist':stats.pareto,
			 'translate': lambda a, b: (a, 0, b),
			 'project': emma},
	    'gev':	{'name':'genextreme',
			 'dist':stats.genextreme,
			 'translate': lambda a, b, c: (a, b, c),
			 'project': emma}
}

def compute_gev_params(iterdata):
	# lengths
	runtime = iterdata.interval_max_usec.sum()
	gev, ci = gevfit.fit_ci(iterdata.interval_max_usec)

	statistic, crit, sig = stats.anderson(iterdata.interval_max_usec, dist='gumbel_r')
	if (statistic > crit[2]):
		print('WARNING: Rejecting null hypothesis that actual interval lengths fit to GEV {0}\n'.format(gev),
        	      '        fit Gumbel_R for p={0:.6f} (AD={1:.6f} > {2})'.format(sig[2]/100, statistic, crit[2]))
	else:
		print('Cannot reject null hyposthsis that actual interval lengths fit to GEV {0} c\n'.format(gev),
	      	      '        fit Gumbel_R for p={0:.6f} (AD={1:.6f} < {2})'.format(sig[2]/100, statistic, crit[2]))
	return gev, ci, statistic

def find_empirical_distribution(iterdata):
	params = stats.norm.fit(iterdata.workload_usec)
	statistic, crit, sig = stats.anderson(iterdata.workload_usec, dist='norm')
	confidence = 0.05
	if (statistic > crit[2]):
		print('WARNING: Rejecting null hypothesis that workload lengths fit to gaussian {0}\n'.format(params),
        	      '        fit normal distribution for p={0:.6f} (A2={1:.6f} > {2})'.format(sig[2]/100, statistic, crit[2]))
	else:
		print('Cannot reject null hypothesis that workload lengths fit to gaussian {0}\n'.format(params),
	  	      '        fit normal distribution for p={0:.6f} (AD={1:.6f} < {2})'.format(sig[2]/100, statistic, crit[2]))
	return params

# Compute the projected runtime of a program with the base single-node
# distribution and a large number of ranks
def project_runtime(distribution, params, iterations, ranks):
	oparams = distmap[distribution]['translate'](*params)
	odist = distmap[distribution]['dist'](*oparams)
	return distmap[distribution]['project'](odist, ranks)*iterations

def compute_ehalf(distribution, a, b, intertions, ranks, gev):

	gevparam = row['actual_gev']
	gevdist = stats.genextreme(*gevparam)

	# Sample-projected runtime on 1 block is just the expected value of the GEV distribution
	runtime_sample_emma = [gevdist.moment(4)*iterations/1000000]

	# Distribution-projected runtime based on either the original distribution or its EMMA
	# project to the initial number of ranks
	rank = ranks
	if rank == 0:
        	runtime_original_emma = [odist.moment(1)*iterations/1000000]
	else:
		runtime_original_emma = [emma(odist, rank)*iterations/1000000]

	# And project everything to more ranks
	rank_list =[]
	for i in range(1, 5):
		rank = ranks*(2**i)
		rank_list.append(rank)
	runtime_sample_emma.append(emma(gevdist, 2**i)*iterations/1000000)
	runtime_original_emma.append(emma(odist, rank)*iterations/1000000)

	# For each set of distributions and parameters, project runtimes from smallest
	# experiment and plot larger experiments versus this projection
	for frame in expdata.groupby(['workload', 'a', 'b', 'iterations']):
		exps = frame[1].sort_values(['ranks']).reset_index(drop=True)
		print('Projecting runtimes for experiment {0}'.format(frame[0]))

		fig, ax = plt.subplots()
		runtimes = []
		sizes = []
		for iter, row in exps.iterrows():
			sizes.append(row['ranks'])
			runtimes.append(row['runtime']/1000000)
			if iter == 0:
				project_runtimes(frame[0], row, fig, ax)
			ax.scatter(sizes, runtimes, label='Actual Runtimes')
			ax.grid()
			plt.legend(bbox_to_anchor=(1.04,1), loc="upper left")
			plt.show()


def process_gev_data(trace_uri):
	print('Processing file {0}'.format(trace_uri))

	with open(trace_uri) as f:
		newT = f.read().replace(']\n[', ',')
	with open(trace_uri, 'w') as f:
		f.write(newT)

	iterdata = construct_dataframe(trace_uri)
	print(iterdata.head())

	workload = iterdata['workload'].values[0]
	a = iterdata['a'].values[0]
	b = iterdata['b'].values[0]
	stencil_size = iterdata['stencil_size'].values[0]
	ranks = iterdata['comm_size'].values[0]
	iterations = iterdata['iterations'].values[0]
	#the number of iterations for the inner loop inside the main loop of  barrier_loop
	inner_loop_itr = iterdata['inner_loop_itr'].values[0]
	params = (a, b)
	print('Analyzing {} {} with {}-byte stencil on {} ranks for {} iterations'.format(workload, params, stencil_size, ranks, iterations))

	actual_runtime = iterdata['interval_max_usec'].sum()

	# If we're doign a stencil or running a dgemm, then we assume the
	# resulting workload is actually gaussian and estimate it
	if (workload == "dgemm") or (stencil_size > 0):
		distribution = "gaussian"
		params = find_empirical_distribution(iterdata)
	elif (workload == "sleep" or workload == "fwq" or workload == "spmv" or workload == "hpcg" or workload == "lammps"):
		distribution = "gaussian"
	elif (workload == "io"):
		distribution = "genextreme"
		params, ci, statistic = compute_gev_params(iterdata)
	else:
		distribution = workload

	projected_runtime = project_runtime(distribution, params, iterations, ranks)
	efficiency = projected_runtime / actual_runtime
	mlflow.log_metric("actual_runtime", actual_runtime)
	mlflow.log_metric("projected_runtime", projected_runtime)
	mlflow.log_metric("efficiency", efficiency)

	gev, ci, statistic = compute_gev_params(iterdata)
	mlflow.log_metric("gev_shape", gev[0])
	mlflow.log_metric("gev_shape_low", ci[0][0])
	mlflow.log_metric("gev_shape_high", ci[0][1])
	mlflow.log_metric("gev_location", gev[1])
	mlflow.log_metric("gev_location_low", ci[1][0])
	mlflow.log_metric("gev_location_high", ci[1][1])
	mlflow.log_metric("gev_scale", gev[2])
	mlflow.log_metric("gev_scale_low", ci[2][0])
	mlflow.log_metric("gev_scale_high", ci[2][1])
	mlflow.log_metric("gev_gumbel_statistic", statistic)

if __name__ == '__main__':
	iterdata = process_gev_data()
